# Big-Data-Analytics
This repository demonstrates big data processing, visualization, and machine learning using tools such as Hadoop, Spark, Kafka, and Python.

<img src = "https://th.bing.com/th/id/R.8332a2c65eeaecfb365ec3a11e9c2b0e?rik=a86A6oZLes5OWw&riu=http%3a%2f%2ftimesquareit.com%2fimages%2fsl-1.jpg&ehk=VKCM0JR5%2b2hM2HSb%2b%2f6w88WsQFhqxkY3pnZymVms7mo%3d&risl=&pid=ImgRaw&r=0">

## Python

Python is a high-level, interpreted programming language known for its readability and versatility. It is widely used in data science for tasks such as data manipulation, analysis, and visualization. Libraries such as Pandas, Matplotlib, and Scikit-Learn provide powerful tools for handling and analyzing large datasets.

## Hadoop

Hadoop is an open-source framework that allows for the distributed processing of large datasets across clusters of computers using simple programming models. It is designed to scale up from a single server to thousands of machines, each offering local computation and storage. Hadoop's core components include the Hadoop Distributed File System (HDFS) for storage and MapReduce for processing data.

## MapReduce

MapReduce is a programming model used for processing and generating large datasets with a parallel, distributed algorithm on a cluster. The model consists of two main tasks:
1. **Map:** Processes input data and produces intermediate key-value pairs.
2. **Reduce:** Merges all intermediate values associated with the same key and outputs the final result.

## Experiments

### 1. Hadoop Installation

**Description:** 
This experiment involves the installation and setup of Hadoop on your system. It covers the necessary configurations to get Hadoop up and running, allowing you to explore its capabilities for handling large-scale data processing tasks.

### 2. Data Exploration with Hadoop

**Description:**
In this experiment, we will use Hadoop to explore large-scale datasets stored in the Hadoop Distributed File System (HDFS). Perform basic operations such as listing files, reading data, and calculating summary statistics.

### 3. Word Count with MapReduce

**Description:**
Implemented the classic MapReduce word count algorithm to count the frequency of words in a large text corpus stored in HDFS. This experiment demonstrates the power of MapReduce for processing and analyzing large volumes of text data.

## Additional Resources

- **Detailed Documentation:** A Word document explaining each command used in the experiments.
- **Output Document:** A document showcasing the outputs and results for each experiment.
